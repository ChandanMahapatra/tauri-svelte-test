# AI-Powered Markdown Editor

A comprehensive Markdown editor with AI-powered text evaluation, built with Tauri (desktop) and modern web technologies. Features real-time preview, grammar checking, readability analysis, and AI scoring.

## ‚ú® Features

- **Real-time Markdown editing** with live preview
- **AI-powered text evaluation** with scoring (0-100)
- **Grammar and readability analysis** with issue highlighting
- **Multiple AI integrations** (LM Studio, OpenAI)
- **Settings persistence** and customizable AI providers
- **Responsive design** for desktop and mobile

## üöÄ Quick Start

### Prerequisites

- **Node.js** (v18 or higher)
- **Rust** (for desktop version)
- **LM Studio** or other AI provider (optional, for AI features)

### Installation

1. **Clone and install dependencies:**
   ```bash
   git clone <repository-url>
   cd markdown-editor
   npm install
   ```

## üñ•Ô∏è Desktop Version (Recommended)

The desktop version provides full AI integration with local models.

### Setup LM Studio (Recommended AI Provider)

1. **Download and install LM Studio:**

   - Visit [https://lmstudio.ai/](https://lmstudio.ai/)
   - Download and install for your platform

2. **Download a model:**

   - Open LM Studio
   - Go to "My Models" tab
   - Search for and download a model like:
     - `mistralai/Mistral-7B-Instruct-v0.1`
     - `microsoft/DialoGPT-medium`
     - `mistralai/magistral-small-2509` (recommended for speed)

3. **Load the model:**

   - Go to "Chat" or "Local Server" tab
   - Load your downloaded model
   - Start the local server (usually on `http://localhost:1234`)

4. **Configure the app:**
   - Run: `npm run tauri dev`
   - Open Settings (gear icon)
   - Set **Provider** to "LM Studio"
   - Set **API URL** to `http://localhost:1234/v1/completions`
   - Set **Model** to match your loaded model (e.g., `mistralai/mistral-7b-instruct-v0.1`)
   - Click "Save Settings"

### Alternative AI Providers

#### Ollama (Local AI)

```bash
# Install Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# Pull a model
ollama pull llama3.2

# Run the app
npm run tauri dev
# In settings: Provider="Local AI", URL="http://localhost:11434/api/generate"
```

#### OpenAI (Cloud)

- Get API key from [OpenAI](https://platform.openai.com/api-keys)
- In settings: Provider="OpenAI", enter your API key

### Running Desktop Version

```bash
npm run tauri dev
```

This launches a native desktop application with full AI capabilities.

## üîí Privacy & Security

**Local-First Architecture** - Your data never leaves your device:

- ‚úÖ **No cloud uploads** - All AI processing happens locally
- ‚úÖ **No internet required** - Works offline with local models
- ‚úÖ **Secure storage** - Settings saved locally with Tauri's encrypted store
- ‚úÖ **Private AI** - Models run on your hardware, not sent to servers
- ‚úÖ **Open source** - Transparent code you can inspect and modify

**Supported Local AI Options:**

- **LM Studio** - Run models locally with GPU acceleration
- **Ollama** - Cross-platform local AI server

## üìä AI Evaluation Features

### Text Analysis

- **Grammar checking** with error highlighting
- **Readability scoring** (sentence complexity, word choice)
- **Style analysis** (passive voice, adverbs, wordiness)
- **Issue identification** with specific suggestions

### AI Scoring

- **0-100 scale** with categorized feedback
- **Multiple criteria**: Grammar, readability, clarity
- **Detailed issue reports** with actionable suggestions
- **Real-time analysis** as you type

### Supported Models

- **LM Studio**: Local models with OpenAI-compatible API
- **Ollama**: Local models with custom API
- **OpenAI**: Cloud-based GPT models

## ü§ñ AI-Assisted Development

This application was built using an **AI-first development approach** with minimal manual coding. The entire codebase was generated and refined using advanced AI language models to explore the capabilities of modern AI programming assistants.

### AI Models Used in Development

**Primary Models:**

- **Qwen3 Coder 480B A35B** - Main development model for code generation and architecture
- **x-ai/grok-code-fast-1** - Fast iteration and code optimization
- **GPT-4.1** - Complex logic and UI component design
- **GPT-5** - Advanced reasoning and system architecture
- **Claude Sonnet 4** - Code review, security analysis, and documentation

### Development Methodology

**"Vibe Coding" Approach:**

- **Minimal manual intervention** - AI generated 95%+ of the codebase
- **Iterative refinement** - AI models collaborated to improve and optimize code
- **Multi-model validation** - Different AIs cross-checked each other's work
- **Automated testing** - AI-generated test cases and validation logic

**Key Achievements:**

- ‚úÖ **Full-stack application** built with AI assistance
- ‚úÖ **Multiple AI integrations** implemented via AI guidance
- ‚úÖ **Security-focused architecture** designed by AI analysis
- ‚úÖ **Comprehensive documentation** generated by AI

### Why This Matters

This project demonstrates the current state of **AI-assisted software development**:

- **Rapid prototyping** with AI-generated boilerplate
- **Intelligent architecture** decisions made by advanced models
- **Quality assurance** through multi-model validation
- **Innovation acceleration** using AI for complex problem-solving

The result is a **production-ready application** that showcases what modern AI can achieve in software development, from concept to deployment, with minimal human intervention.

## üõ†Ô∏è Development

### Project Structure

```
‚îú‚îÄ‚îÄ src/                    # Svelte frontend
‚îÇ   ‚îú‚îÄ‚îÄ App.svelte         # Desktop version main component
‚îÇ   ‚îú‚îÄ‚îÄ lib/               # Shared components
‚îÇ   ‚îî‚îÄ‚îÄ main.ts            # Desktop entry point
‚îú‚îÄ‚îÄ src-tauri/             # Tauri backend (Rust)
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.rs        # Tauri app entry
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ lib.rs         # Core logic & AI integration
‚îÇ   ‚îî‚îÄ‚îÄ tauri.conf.json    # Tauri configuration
‚îî‚îÄ‚îÄ package.json          # Dependencies & scripts
```

### Available Scripts

```bash
npm run dev          # Vite dev server (for debugging)
npm run tauri dev    # Desktop app development
npm run build        # Production build
npm run preview      # Preview production build
```

### Key Technologies

- **Frontend:** Svelte 5, TypeScript, Tailwind CSS
- **Desktop:** Tauri (Rust backend for security)
- **AI Integration:** Multiple providers with unified API
- **Text Analysis:** Custom algorithms + AI evaluation
- **Storage:** Tauri's secure store (desktop)

## üîß Configuration

### Settings Options

- **Provider**: Choose AI service (LM Studio, OpenAI, Local AI)
- **API URL**: Endpoint for AI service
- **Model**: Specific model to use
- **API Key**: For cloud services (stored securely)

### Troubleshooting

**Desktop Version Issues:**

- Ensure LM Studio/Ollama server is running
- Check API URL matches your server configuration
- Verify model is loaded in your AI application

## üìà Performance

- **Desktop**: Full AI inference with local models (fast, private)
- **Real-time**: Analysis updates as you type
- **Efficient**: Optimized for smooth editing experience

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test desktop version
5. Submit a pull request

## üìÑ License

MIT License - see LICENSE file for details.

## üôè Acknowledgments

- [Tauri](https://tauri.app/) - Secure desktop app framework
- [Svelte](https://svelte.dev/) - Reactive UI framework
- [LM Studio](https://lmstudio.ai/) - Local AI model platform

---

**Ready to write better content?** Start with `npm run tauri dev` and explore AI-powered writing assistance!
